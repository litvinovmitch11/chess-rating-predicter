{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T07:10:45.332439Z",
     "start_time": "2024-06-06T07:10:45.003247Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ],
   "id": "41323af23da6665d",
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T07:10:46.004697Z",
     "start_time": "2024-06-06T07:10:45.888337Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from modules.utils.rating_to_category import rating_to_number\n",
    "from modules.chessPreprocessor.preprocessor import Preprocessor\n",
    "import chess.pgn"
   ],
   "id": "fd8b14bfffe1d611",
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Попробуем собрать статистику по 1 игре",
   "id": "5efca8eb4c082d78"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T07:10:46.779558Z",
     "start_time": "2024-06-06T07:10:46.649373Z"
    }
   },
   "cell_type": "code",
   "source": [
    "proc_first = Preprocessor()\n",
    "required_headers = ['Event', 'Result', 'WhiteElo', 'BlackElo', 'WhiteRatingDiff', 'BlackRatingDiff', 'ECO', 'Opening',\n",
    "                    'TimeControl', 'Termination']\n",
    "with open(\"../data/lichess_db_standard_rated_2013-01.pgn\") as pgn:\n",
    "    while True:\n",
    "        game = chess.pgn.read_game(pgn)\n",
    "        if game is None:\n",
    "            break\n",
    "        if not all(header in game.headers for header in required_headers) or '?' in game.headers['Event'] + \\\n",
    "                game.headers['Result'] + game.headers['WhiteElo'] + game.headers['BlackElo'] + game.headers[\n",
    "            'WhiteRatingDiff'] + game.headers['BlackRatingDiff'] + game.headers['ECO'] + game.headers[\n",
    "            'Opening'] + game.headers['TimeControl'] + game.headers['Termination']:\n",
    "            continue\n",
    "        proc_first.read_pgn_from_string(str(game.mainline_moves()))\n",
    "        break"
   ],
   "id": "de2cf03f8f9c4383",
   "execution_count": 3,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Засечем время, за которое мы получаем статистику по 1 игре",
   "id": "9bed2333e649a629"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T07:11:44.785445Z",
     "start_time": "2024-06-06T07:10:47.613395Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%time\n",
    "proc_first.calculate_wdl()\n",
    "proc_first.calculate_evaluation_stat()\n",
    "proc_first.calculate_n_best_lines(n=3)"
   ],
   "id": "4752896962461ad2",
   "execution_count": 4,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Видим, что если мы захотим собрать статистику по большому датасету, то ударимся об то, что это будет НУ ОЧЕНЬ долго. Давайте попробуем ускорить этот процесс (начнем с разных процессов). Для начала поймем в каком формате хотим хранить данные. Давайте запоминать id игры, номер хода и сохранять всю имеющуюся статистику. Также будем хранить id для наших игр. Таким образом создадим свзять между датасетами",
   "id": "70b27beae7ba4820"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T07:11:44.812535Z",
     "start_time": "2024-06-06T07:11:44.787760Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_stat_first = proc_first.get_stats_per_move(add_wdl_stats=True, add_evaluation_stats=True, n_best_lines=3)\n",
    "df_stat_first['game_id'] = 0\n",
    "df_stat_first['move_number'] = np.arange(df_stat_first['game_id'].shape[0])\n",
    "df_stat_first.head(3)"
   ],
   "id": "80282db6c75ed612",
   "execution_count": 5,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Отлично! Такой формат нас более чем устроит. Запомним его, дальше он нам пригодится",
   "id": "ac9f1990e6c4d806"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Но вот незадача, мы не знаем размеры нашего датафрейма. Давайте посмотрим на распределение классов. Хорошо что мы уже получали весь датафрейм, воспользуемся им",
   "id": "1027850acd31af3f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T07:11:46.116763Z",
     "start_time": "2024-06-06T07:11:44.814683Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.read_csv('../data/lichess_db_standard_rated_2013-01.csv')\n",
    "df['white_rating_num'] = df['white_elo'].apply(rating_to_number)\n",
    "df['black_rating_num'] = df['black_elo'].apply(rating_to_number)\n",
    "df['white_rating_num'].value_counts()"
   ],
   "id": "898002bcf023d7b8",
   "execution_count": 6,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T07:11:46.128931Z",
     "start_time": "2024-06-06T07:11:46.119657Z"
    }
   },
   "cell_type": "code",
   "source": "df['black_rating_num'].value_counts()",
   "id": "b7b68d24e0895c15",
   "execution_count": 7,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Мы знаем, что одна игра обрабатывается ~1 минуту. Если мы спим ~6 часов, тогда нам хватит на 360 игр! Тогда давайте возьмем с каждого класса ~500 игр, но т.к. в игре могут играть разные классы, то ~1000 участников с каждым рейтингом. Тогда посчитаем количество игр, которые будут в итоговом датасете",
   "id": "2d1793682b35f8d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T07:17:48.278319Z",
     "start_time": "2024-06-06T07:11:46.130693Z"
    }
   },
   "cell_type": "code",
   "source": [
    "proc = Preprocessor()\n",
    "MAX_USER_NUM = 1000\n",
    "rating_num_count = {0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0}\n",
    "\n",
    "i = 0\n",
    "required_headers = ['Event', 'Result', 'WhiteElo', 'BlackElo', 'WhiteRatingDiff', 'BlackRatingDiff', 'ECO', 'Opening',\n",
    "                    'TimeControl', 'Termination']\n",
    "with open(\"../data/lichess_db_standard_rated_2013-01.pgn\") as pgn:\n",
    "    while True:\n",
    "        game = chess.pgn.read_game(pgn)\n",
    "        if game is None:\n",
    "            break\n",
    "\n",
    "        if not all(header in game.headers for header in required_headers) or '?' in game.headers['Event'] + \\\n",
    "                game.headers['Result'] + game.headers['WhiteElo'] + game.headers['BlackElo'] + game.headers[\n",
    "            'WhiteRatingDiff'] + game.headers['BlackRatingDiff'] + game.headers['ECO'] + game.headers[\n",
    "            'Opening'] + game.headers['TimeControl'] + game.headers['Termination']:\n",
    "            continue\n",
    "        white_elo = int(game.headers['WhiteElo'])\n",
    "        white_num = rating_to_number(white_elo)\n",
    "\n",
    "        black_elo = int(game.headers['BlackElo'])\n",
    "        black_num = rating_to_number(black_elo)\n",
    "        if rating_num_count[white_num] < MAX_USER_NUM or rating_num_count[black_num] < MAX_USER_NUM:\n",
    "            rating_num_count[white_num] += 1\n",
    "            rating_num_count[black_num] += 1\n",
    "            i += 1\n",
    "i"
   ],
   "id": "d0d96c78d660b6ad",
   "execution_count": 8,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Не густо, но будем работать с чем имеем. Если поймем, что данных мало, то на этот случай сохраним индексы игр в датасете, чтобы сохранять игры, на которых мы уже обучились\n",
    "\n",
    "Теперь самое интересное, давай сохраним в 2 датасета:\n",
    "1) Информацию о всей партии\n",
    "2) Информацию про ходы для каждой партии\n",
    "Сохранять мы будем для того, чтобы читать данные из csv, что хотя-бы реально по времени"
   ],
   "id": "f4d72d6b2d276f9a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T07:24:26.284476Z",
     "start_time": "2024-06-06T07:17:48.280650Z"
    }
   },
   "cell_type": "code",
   "source": [
    "proc = Preprocessor()\n",
    "rating_num_count = {0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0}\n",
    "GAME_COUNT = i\n",
    "\n",
    "i = 0\n",
    "game_id = 0\n",
    "required_headers = ['Event', 'Result', 'WhiteElo', 'BlackElo', 'WhiteRatingDiff', 'BlackRatingDiff', 'ECO', 'Opening',\n",
    "                    'TimeControl', 'Termination']\n",
    "\n",
    "events = np.empty(GAME_COUNT, dtype=object)\n",
    "results = np.empty(GAME_COUNT, dtype=object)\n",
    "\n",
    "white_elo = np.empty(GAME_COUNT, dtype=int)\n",
    "black_elo = np.empty(GAME_COUNT, dtype=int)\n",
    "white_rating_diff = np.empty(GAME_COUNT, dtype=int)\n",
    "black_rating_diff = np.empty(GAME_COUNT, dtype=int)\n",
    "\n",
    "ecos = np.empty(GAME_COUNT, dtype=object)\n",
    "openings = np.empty(GAME_COUNT, dtype=object)\n",
    "\n",
    "time_control = np.empty(GAME_COUNT, dtype=object)\n",
    "termination = np.empty(GAME_COUNT, dtype=object)\n",
    "\n",
    "game_ids = np.empty(GAME_COUNT, dtype=int)\n",
    "\n",
    "all_moves = []\n",
    "\n",
    "with open(\"../data/lichess_db_standard_rated_2013-01.pgn\") as pgn:\n",
    "    while True:\n",
    "        game = chess.pgn.read_game(pgn)\n",
    "        if game is None:\n",
    "            break\n",
    "\n",
    "        if not all(header in game.headers for header in required_headers) or '?' in game.headers['Event'] + \\\n",
    "                game.headers['Result'] + game.headers['WhiteElo'] + game.headers['BlackElo'] + game.headers[\n",
    "            'WhiteRatingDiff'] + game.headers['BlackRatingDiff'] + game.headers['ECO'] + game.headers[\n",
    "            'Opening'] + game.headers['TimeControl'] + game.headers['Termination']:\n",
    "            continue\n",
    "        game_white_elo = int(game.headers['WhiteElo'])\n",
    "        white_num = rating_to_number(game_white_elo)\n",
    "\n",
    "        game_black_elo = int(game.headers['BlackElo'])\n",
    "        black_num = rating_to_number(game_black_elo)\n",
    "        if rating_num_count[white_num] < MAX_USER_NUM or rating_num_count[black_num] < MAX_USER_NUM:\n",
    "            rating_num_count[white_num] += 1\n",
    "            rating_num_count[black_num] += 1\n",
    "\n",
    "            events[i] = game.headers['Event']\n",
    "            results[i] = game.headers['Result']\n",
    "            white_elo[i] = game_white_elo\n",
    "            black_elo[i] = game_black_elo\n",
    "            white_rating_diff[i] = game.headers['WhiteRatingDiff']\n",
    "            black_rating_diff[i] = game.headers['BlackRatingDiff']\n",
    "            ecos[i] = game.headers['ECO']\n",
    "            openings[i] = game.headers['Opening']\n",
    "            time_control[i] = game.headers['TimeControl']\n",
    "            termination[i] = game.headers['Termination']\n",
    "            game_ids[i] = game_id\n",
    "\n",
    "            all_moves.append(str(game.mainline_moves()))\n",
    "            i += 1\n",
    "        game_id += 1\n",
    "\n",
    "df = pd.DataFrame({'Events': events, 'results': results, 'white_elo': white_elo, 'black_elo': black_elo,\n",
    "                   'white_rating_diff': white_rating_diff, 'black_rating_diff': black_rating_diff, 'ecos': ecos,\n",
    "                   'openings': openings, 'time_control': time_control, 'termination': termination,\n",
    "                   'game_id': game_ids})\n"
   ],
   "id": "f17cafa51acdd863",
   "execution_count": 9,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T07:24:26.305402Z",
     "start_time": "2024-06-06T07:24:26.285817Z"
    }
   },
   "cell_type": "code",
   "source": "df.head(5)",
   "id": "7b2364fcf435f714",
   "execution_count": 10,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Запишем этот data_frame в csv, чтобы с ним можно было быстрее работать",
   "id": "bb90e0ccabadb65c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T08:20:40.861329Z",
     "start_time": "2024-06-06T08:20:40.828611Z"
    }
   },
   "cell_type": "code",
   "source": "df.to_csv(\"../data/clear_data.csv\", encoding='utf-8', index=False)",
   "id": "33feca910e1e156a",
   "execution_count": 27,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Теперь давайте напишем функцию, которая будет принимать отрезок ходов, которые мы хотим обрабатывать, соответсвующие индексы ",
   "id": "bb42243134a69586"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T07:25:03.749417Z",
     "start_time": "2024-06-06T07:25:03.735408Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_preprocessed_df(l, r, moves, _game_ids):\n",
    "    # count in [l, r)\n",
    "    _all_stats = []\n",
    "    for ind in range(l, r, 1):\n",
    "        _proc = Preprocessor()\n",
    "        _proc.read_pgn_from_string(moves[ind])\n",
    "        _proc.calculate_wdl()\n",
    "        _proc.calculate_evaluation_stat()\n",
    "        _proc.calculate_n_best_lines(n=3)\n",
    "        df_stat = _proc.get_stats_per_move(add_wdl_stats=True, add_evaluation_stats=True, n_best_lines=3)\n",
    "        df_stat['game_id'] = _game_ids[ind]\n",
    "        df_stat['move_number'] = np.arange(df_stat['game_id'].shape[0])\n",
    "        _all_stats.append(df_stat)\n",
    "\n",
    "    return _all_stats"
   ],
   "id": "fd3183972fdf6a08",
   "execution_count": 13,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Давайте проверим, действительно ли с потоками программа будет выполняться быстрее. Для этого засечем время и проверим на отрезке [0, 9)",
   "id": "397c426634689c3a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T07:38:05.947835Z",
     "start_time": "2024-06-06T07:25:15.698526Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%time\n",
    "all_stats_without_thread = get_preprocessed_df(0, 9, all_moves, game_ids)"
   ],
   "id": "72c48e8d1726812f",
   "execution_count": 14,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T07:46:06.895452Z",
     "start_time": "2024-06-06T07:38:58.239884Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%time\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    future1 = executor.submit(get_preprocessed_df, 0, 3, all_moves, game_ids)\n",
    "    future2 = executor.submit(get_preprocessed_df, 3, 6, all_moves, game_ids)\n",
    "    future3 = executor.submit(get_preprocessed_df, 6, 9, all_moves, game_ids)\n",
    "\n",
    "    return1 = future1.result()\n",
    "    return2 = future2.result()\n",
    "    return3 = future3.result()\n",
    "\n",
    "len(return1 + return2 + return3)"
   ],
   "id": "77e3722234d263b4",
   "execution_count": 16,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Прирост хоть и не в 3 раза, но какой-то да есть. Давайте попробуем запустить процессы и посмотреть как долго они будут работать. Для них нужна своя фунция, которая будет принимать очередь (с помощью которой умеют общаться потоки)",
   "id": "6412e2c89192b256"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T07:50:16.342535Z",
     "start_time": "2024-06-06T07:50:16.336234Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_preprocessed_df_in_process(l, r, moves, _game_ids, return_dict, process_id):\n",
    "    # count in [l, r)\n",
    "    _all_stats = []\n",
    "    for ind in range(l, r, 1):\n",
    "        _proc = Preprocessor()\n",
    "        _proc.read_pgn_from_string(moves[ind])\n",
    "        _proc.calculate_wdl()\n",
    "        _proc.calculate_evaluation_stat()\n",
    "        _proc.calculate_n_best_lines(n=3)\n",
    "        df_stat = _proc.get_stats_per_move(add_wdl_stats=True, add_evaluation_stats=True, n_best_lines=3)\n",
    "        df_stat['game_id'] = _game_ids[ind]\n",
    "        df_stat['move_number'] = np.arange(df_stat['game_id'].shape[0])\n",
    "        _all_stats.append(df_stat)\n",
    "    return_dict[process_id] = _all_stats"
   ],
   "id": "f1bd6aa57e521815",
   "execution_count": 18,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T07:57:58.206868Z",
     "start_time": "2024-06-06T07:50:45.158833Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%time\n",
    "from multiprocessing import Process, Manager\n",
    "\n",
    "with Manager() as manager:\n",
    "    return_dict = manager.dict()\n",
    "    processes = [\n",
    "        Process(target=get_preprocessed_df_in_process, args=(i * 3, (i + 1) * 3, all_moves, game_ids, return_dict, i))\n",
    "        for i in range(3)]\n",
    "    for p in processes:\n",
    "        p.start()\n",
    "    for p in processes:\n",
    "        p.join()\n",
    "    print(len(list(return_dict.values())))\n"
   ],
   "id": "85b1dafe7e06fc86",
   "execution_count": 20,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Процессы нас тоже не спасли (почему-то). Тогда давайте напишем на потоках, прочитаем первые 240 записей из 8 потоков. Для этого сначала проверим что результаты потоки вернули верные (сравним их с результатами 1 потока), а затем поставим так скажем на загрузгу наши потоки",
   "id": "a6064d6d4ed8bdb2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "8 потоков обрабатывали (каждый) 1 игру в сумме 4 минуты. Что примерно 30 секунд на игру\n",
    "16 потоков обрабатывали (каждый) 1 игру в сумме 8 минуты. Что примерно также 30 секунд на игру. Поэтому оставим 8 потоков "
   ],
   "id": "4deb1698e7db8b79"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T12:31:12.303463Z",
     "start_time": "2024-06-06T09:52:18.131048Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%time\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "THREAD_COUNT = 8\n",
    "STEP = 30\n",
    "all_res = []\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    all_future = [executor.submit(get_preprocessed_df, i * STEP, (i + 1) * STEP, all_moves, game_ids) for i in\n",
    "                  range(THREAD_COUNT)]\n",
    "    for future in all_future:\n",
    "        all_res += future.result()\n",
    "len(all_res)"
   ],
   "id": "1d0cb50922664385",
   "execution_count": 31,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T12:31:12.330608Z",
     "start_time": "2024-06-06T12:31:12.304840Z"
    }
   },
   "cell_type": "code",
   "source": "all_res[239]",
   "id": "341b2ed834d72539",
   "execution_count": 32,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T12:31:12.657455Z",
     "start_time": "2024-06-06T12:31:12.331782Z"
    }
   },
   "cell_type": "code",
   "source": [
    "res = pd.concat([i for i in all_res])\n",
    "res.to_csv(\"../data/first_240.csv\", encoding='utf-8', index=False)"
   ],
   "id": "61632e3ac9de9553",
   "execution_count": 33,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Предобработаем ещё 120 игр",
   "id": "8227d2de59854807"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T13:53:13.436349Z",
     "start_time": "2024-06-06T12:43:58.680522Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%time\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "THREAD_COUNT = 8\n",
    "STEP = 15\n",
    "all_res_120 = []\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    all_future = [executor.submit(get_preprocessed_df, i * STEP + 240, (i + 1) * STEP + 240, all_moves, game_ids) for i in\n",
    "                  range(THREAD_COUNT)]\n",
    "    for future in all_future:\n",
    "        all_res_120 += future.result()\n",
    "len(all_res_120)"
   ],
   "id": "81396535ba8b8b74",
   "execution_count": 37,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T13:53:13.537706Z",
     "start_time": "2024-06-06T13:53:13.437780Z"
    }
   },
   "cell_type": "code",
   "source": [
    "res_120 = pd.concat([i for i in all_res_120])\n",
    "res_120.to_csv(\"../data/from_240_to_360.csv\", encoding='utf-8', index=False)"
   ],
   "id": "1a18c683c5393c3e",
   "execution_count": 38,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
